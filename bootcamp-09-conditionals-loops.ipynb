{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5d96320",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"earth-lab-logo-rgb.png\" width=\"150\" height=\"150\" />\n",
    "\n",
    "# Earth Analytics Education"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21b6cf4",
   "metadata": {},
   "source": [
    "## Important  - Assignment Guidelines\n",
    "\n",
    "1. Before you submit your assignment to GitHub, make sure to run the entire notebook with a fresh kernel. To do this first, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart & Run All)\n",
    "2. Always replace the `raise NotImplementedError()` code with your code that addresses the activity challenge. If you don't replace that code, your notebook will not run.\n",
    "\n",
    "```\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "```\n",
    "\n",
    "3. Any open ended questions will have a \"YOUR ANSWER HERE\" within a markdown cell. Replace that text with your answer also formatted using Markdown.\n",
    "4. **DO NOT RENAME THIS NOTEBOOK File!** If the file name changes, the autograder will not grade your assignment properly.\n",
    "\n",
    "* Only include the package imports, code, and outputs that are required to run your homework assignment.\n",
    "* Be sure that your code can be run on any operating system. This means that:\n",
    "   1. the data should be downloaded in the notebook to ensure it's reproducible\n",
    "   2. all paths should be created dynamically using the `os.path.join`\n",
    "   3. sort lists of dated files even if they are sorted correctly by default on your machine\n",
    "\n",
    "## Follow to PEP 8 Syntax Guidelines & Documentation\n",
    "\n",
    "* Run the `autopep8` tool on all cells prior to submitting (HINT: hit shift + the tool to run it on all cells at once!\n",
    "* Use clear and expressive names for variables. \n",
    "* Organize your code to support readability.\n",
    "* Check for code line length\n",
    "* Use comments and white space sparingly where it is needed\n",
    "* Make sure all python imports are at the top of your notebook and follow PEP 8 order conventions\n",
    "* Spell check your Notebook before submitting it.\n",
    "\n",
    "For all of the plots below, be sure to do the following:\n",
    "\n",
    "* Make sure each plot has a clear TITLE and, where appropriate, label the x and y axes. Be sure to include UNITS in your labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a694cce0",
   "metadata": {},
   "source": [
    "### Add Your Name Below \n",
    "**Your Name:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e8f3a0",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"colored-bar.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de76c6f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3223e12",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63d77091b6538e8bc025993bee395c49",
     "grade": false,
     "grade_id": "overview",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Thomas Fire: Leaf Area Index\n",
    "\n",
    "One of the effects of wildfire is to decrease vegetation. In this notebook, you will use earth observations from the MODIS platform to visualize changes in vegetation due to California's Thomas Fire of 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a934bd3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "df1c02ed98d35daae885ef0919e6cf47",
     "grade": false,
     "grade_id": "instr-imports",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 1: Set up an interoperable analysis\n",
    "\n",
    "### Imports\n",
    "In the cell below, import necessary packages to:\n",
    "  * Define interoperable file paths\n",
    "  * Work with vector data\n",
    "  * Work with raster data\n",
    "  * Generate sequences of dates (HINT: what package did we use for time series data?)\n",
    "  * Generate plots\n",
    "  \n",
    "In addition, you will need the `requests` library to download data in the JSON format, the numpy (as np) library to work with arrays, and the `json` **standard library** to cache your downloads in .json files, and the `clear_output` function from the `IPython.display` library for creating animations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a313268",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f877ce12e05fcb22ab76b793ec817d4",
     "grade": false,
     "grade_id": "ans-import",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0cddf7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26859903a1868f4e9ecf2531139eae0c",
     "grade": true,
     "grade_id": "tests-import",
     "locked": true,
     "points": 9,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import_pts = 0\n",
    "\n",
    "libraries = [\n",
    "    'json', 'os', 'gpd', 'clear_output', 'np', 'plt', 'pd', 'requests', 'rxr'\n",
    "]\n",
    "\n",
    "for library in libraries:\n",
    "    try:\n",
    "        exec(library)\n",
    "        print('\\u2705 Correctly imported {}'.format(library))\n",
    "        import_pts += 1\n",
    "    except:\n",
    "        print('\\u274C Missing {}'.format(library))\n",
    "        \n",
    "print('You received {} of 9 points for imports.'.format(import_pts))\n",
    "import_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b7c9dd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c0ae3f7b5e59c071b175082200a3808e",
     "grade": false,
     "grade_id": "task-wd-conditional",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Working Directory\n",
    "In the cell below, change your working directory so that your code will be interoperable. Create two directories for:\n",
    "  * the Thomas Fire perimeter shapefile, `thomas-fire-perimeter`\n",
    "  * the MODIS LAI data subset downloads, `thomas-modis-lai`\n",
    "  \n",
    "**Please use those names! Otherwise I will have to download the data 30 times, which will take some time.**\n",
    "  \n",
    "Write descriptive, robust, and DRY code to set the directory paths:\n",
    "  * Use conditional statement(s) to check if the directories already exist, and create them if they do not.\n",
    "  * Print out descriptive messages about what your code is doing.\n",
    "  * Instead of writing the code out twice, use a `for` loop to create the directories\n",
    "\n",
    "Call both directory paths at the end of your cell for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffe091a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50776bae848dec2108229ff034139d16",
     "grade": false,
     "grade_id": "ans-wd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb0e63d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1c2348cd36f88d1db6a6ec31f3e9872f",
     "grade": false,
     "grade_id": "task-description",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Site description\n",
    "\n",
    "In the cell below, write a brief site description, citing sources you used to learn about the Thomas Fire. Include:\n",
    "  * Location and dates of the fire\n",
    "  * Size of the fire\n",
    "  * Climate and ecoregion of the surrounding area\n",
    "  * Any natural hazards that occurred as a result of the fire\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c2dca5",
   "metadata": {},
   "source": [
    "YOUR RESPONSE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c2c6db",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2282e1359a8f410afa9e0d600d0118cd",
     "grade": false,
     "grade_id": "task-thomas-download",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Step 2: Download  the Thomas Fire perimeter\n",
    "### Construct a download url\n",
    "Fire perimeter data in the US is available from the [National Interagency Fire Center](https://data-nifc.opendata.arcgis.com/).\n",
    "\n",
    "You can find the Thomas fire perimeter using the following procedure:\n",
    "  1. Open the [National Interagency Fire Center Fire Perimeter API constructor](https://data-nifc.opendata.arcgis.com/datasets/nifc::historic-perimeters-combined-2000-2018-geomac/api) in your web browser.\n",
    "  2. Add an `incidentname` parameter that is like `THOMAS`, a `YEAR` between 2017 and 2018, and a `state` like `CA`\n",
    "  3. Click `Copy to clipboard` to get the url, which you will use to download the data. Save the url to a Python variable in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83eb5ac",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4daaaad7d61aa15fa93cefdbd6ed26b3",
     "grade": false,
     "grade_id": "ans-thomas-download",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63402539",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "86d36de4d50f6cc4b781b229f84c1ef5",
     "grade": false,
     "grade_id": "task-cite",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Cite your data\n",
    "In the cell below, cite the Thomas Fire perimeter data. They do not specify how to cite the data, so you will need to construct a citation in APA format using information from their web page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1059199",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030a1364",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a04bd2e33cc6de4315cd5b2a44e8362",
     "grade": false,
     "grade_id": "inst-download-thomas",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Download and Cache the Thomas Fire perimeter\n",
    "In the cell below, \n",
    "  * Download the Thomas Fire perimeter\n",
    "  * You will get two geometries back from the API. Select the one with the larger area.\n",
    "      > Select the row where the `gisacres` column value is equal to the maximum\n",
    "  * Using a **conditional statement**, make sure to **cache** the single fire perimeter in a shapefile. Your code should load the perimeter from that file if the file already exists.\n",
    "\n",
    "      > Check out the `.to_file` method of your `GeoDataFrame`.\n",
    "    \n",
    "Call the **path** to your GeoDataFrame at the end of the cell for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d468682",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "afdc328fd8815f09e943267bfe4a3a09",
     "grade": false,
     "grade_id": "ans-download-thomas",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db580f87",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aea40e5880b60c8feba10c65c8330287",
     "grade": true,
     "grade_id": "tests-download-thomas",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ans_path = _\n",
    "download_thomas_pts = 0\n",
    "\n",
    "# Test if the file exists\n",
    "if os.path.exists(ans_path):\n",
    "    print('\\u2705 Great! Your file exists.')\n",
    "    download_thomas_pts += 2\n",
    "else:\n",
    "    print('\\u274C {} does not exist'.format(ans_path))\n",
    "    \n",
    "# Test if the file can be loaded by geopandas\n",
    "try:\n",
    "    gpd.read_file(ans_path)\n",
    "    download_thomas_pts += 4\n",
    "    print('\\u2705 Great! Your file contains vector data.')\n",
    "except:\n",
    "    print('\\u274C There is something wrong with your file: {}'\n",
    "          .format(ans_path))\n",
    "    \n",
    "print('You received {} of 6 points for downloading and caching data'\n",
    "      .format(download_thomas_pts))\n",
    "\n",
    "download_thomas_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715bbf0a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f2ae548a623cea015c4dc41a9865d4eb",
     "grade": false,
     "grade_id": "instr-reproject-thomas",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Reproject the Thomas Fire perimeter to match the MODIS projection\n",
    "You will be using MODIS raster data to examine the vegetation. The projection of MODIS data IS NOT CLEAR in the documentation. It is:\n",
    "\n",
    "    +proj=sinu +lon_0=0 +x_0=0 +y_0=0 +a=6371007.181 +b=6371007.181 +units=m +no_defs\n",
    "    \n",
    "Reproject the Thomas Fire Perimeter in the MODIS projection and the call the reprojected `GeoDataFrame` for testing. You can use the PROJ4 projection format above as an argument to the reprojection method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758db523",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e5d18c063bea1f911782bdcee2404283",
     "grade": false,
     "grade_id": "ans-reproject",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282851ab",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e14aa660adc46005a72ecb903b02fa58",
     "grade": true,
     "grade_id": "tests-reproject",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ans_reproject = _\n",
    "reproject_pts = 0\n",
    "\n",
    "correct_crs = (\n",
    "    \"+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +a=6371007.181 +b=6371007.181 \"\n",
    "    \"+units=m +no_defs +type=crs\")\n",
    "correct_bounds = [-10973718, 3811755, -10903862, 3851514]\n",
    "\n",
    "# Test if the response is a GeoDataFrame\n",
    "if isinstance(ans_reproject, gpd.GeoDataFrame):\n",
    "    print('\\u2705 Nice work! Your response is a GeoDataFrame.')\n",
    "    reproject_pts += 1\n",
    "else:\n",
    "    print('\\u274C Please return your reprojected GeoDataFrame'\n",
    "          .format(ans_path))\n",
    "    \n",
    "# Test if the CRS is the MODIS Sinusoidal projection\n",
    "if ans_reproject.crs==correct_crs:\n",
    "    print('\\u2705 Great! Your GeoDataFrame has the correct CRS.')\n",
    "    reproject_pts += 2\n",
    "else:\n",
    "    print('\\u274C Incorrect CRS'.format(ans_path))\n",
    "\n",
    "# Test if the total_bounds of the data is correct\n",
    "if [round(b) for b in ans_reproject.total_bounds]==correct_bounds:\n",
    "    print('\\u2705 Great! Your GeoDataFrame has the correct bounds')\n",
    "    reproject_pts += 2\n",
    "else:\n",
    "    print('\\u274C Incorrect bounds - check your work')\n",
    "    \n",
    "print('You received {} of 5 points for reprojecting the perimeter'\n",
    "      .format(reproject_pts))\n",
    "\n",
    "reproject_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ead52c4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2601137ed79225761bed8537cdd875f7",
     "grade": false,
     "grade_id": "overview-modis",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## MODIS LAI data for the location and time of the Thomas Fire\n",
    "\n",
    "Now that you have prepared your site boundary, you will add [MODIS LAI data, part of the MODIS Land Product collection](https://daac.ornl.gov/cgi-bin/dsviewer.pl?ds_id=1557) to visualize the impact of the Thomas Fire on vegetation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cb0e43",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8bbbf97e5c25bf877c60727e0cd470e7",
     "grade": false,
     "grade_id": "task-cite-modis",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Cite the MODIS LAI data\n",
    "In the cell below, cite the MODIS LAI data. Though it is not required by the citation, you should also make a note of your access date and any other details you would need to get the same data in the future.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b436f8",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e77bd3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "262ad9668a4b4f6b93e2d2b60fd1f5bb",
     "grade": false,
     "grade_id": "task-lai",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Define Leaf Area Index (LAI)\n",
    "\n",
    "In the cell below, explain what leaf area index (LAI) is and why we might expect to see a change in LAI due to wildfire. You should consult the [MODIS LAI User Guide](https://lpdaac.usgs.gov/documents/2/mod15_user_guide.pdf) to check what definition of LAI they use - this is important for comparing with field data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87841bf7",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b3dfb8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "426ec8c57688645d307d0593f7fb2f97",
     "grade": false,
     "grade_id": "task-docs",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Check the documentation\n",
    "\n",
    "You will need to retrieve some key details from the documentation to use these data, since they are not stored in a self-documenting format. At a minimum, you should check:\n",
    "  * Are there nodata values?\n",
    "  * Is the data scaled?\n",
    "  * What is the valid range of LAI values?\n",
    "  * Are the data available at the time and location of the Thomas Fire?\n",
    "  \n",
    "Put the answers you find in the cell below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb27261b",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896ea25d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b578ac4e289bd4dfe51721ed29f0f16d",
     "grade": false,
     "grade_id": "instr-bounds",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Define the data bounds\n",
    "You will need the following values to subset the data:\n",
    "  * The center of the Thomas Fire perimeter as a latitude and longitude\n",
    "  * The number of km above and below the center the perimeter extends\n",
    "  * The number of km to the left and right of the center the perimeter extends\n",
    "  * Start and end date of the study (January 1, 2014 - December 31, 2018) as strings\n",
    "  \n",
    "    > Use the `.total_bounds` attribute of your fire perimeter `GeoDataFrame`s to calculate the spatial values. It may be helpful to draw a diagram.\n",
    "    \n",
    "Call four values for testing: latitude, longitude, km_above_below, km_left_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a97f79",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b626aa68a1720b36bd916a9641ac0b03",
     "grade": false,
     "grade_id": "ans-bounds",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69049dc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bfb2fc15939ea10a132c37d7d2239023",
     "grade": true,
     "grade_id": "tests-bounds",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ans_bound_info = _\n",
    "bound_pts = 0\n",
    "\n",
    "correct_sum = -31.84\n",
    "\n",
    "# Test if there are the correct number of values\n",
    "if len(ans_bound_info)==4:\n",
    "    print('\\u2705 Nice work! You returned the correct number of values.')\n",
    "    bound_pts += 1\n",
    "else:\n",
    "    print('\\u274C Check that you called 4 values'.format(ans_path))\n",
    "    \n",
    "# Test if the values are correct\n",
    "if round(sum(ans_bound_info), 2)==correct_sum:\n",
    "    print('\\u2705 Great! Your values appear to be correct.')\n",
    "    bound_pts += 6\n",
    "else:\n",
    "    print('\\u274C Check your computation - looks like there an error')\n",
    "\n",
    "print('Your received {} of 7 points for defining your data bounds'\n",
    "      .format(bound_pts))\n",
    "bound_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c68de2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e38617a85abf5cb47381f7039e82e9d0",
     "grade": false,
     "grade_id": "instr-dates",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Generate start and end dates for each subset\n",
    "This API only allows you to download 10 dates at a time. You will need to split up your downloads. Use a `for` loop to generate a list of dictionaries that each contain a start and end date for one month of data. Format the dates as '%Y%j', or year followed by day of the year. \n",
    "\n",
    "    > Try using the `pd.date_range` function, with 'MS' and 'M' frequencies, and then zipping together the results\n",
    "    \n",
    "Call your list of dictionaries for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37048e86",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ce5d2eab054662492a7efaa72f06585",
     "grade": false,
     "grade_id": "ans-dates",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ccb93f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "82c80ac5aa533fcc969f8605b46e5537",
     "grade": true,
     "grade_id": "tests-dates",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ans_dates = _\n",
    "dates_pts = 0\n",
    "\n",
    "date_sum = 241941886\n",
    "\n",
    "# Test if the data are a list of dictionaries\n",
    "if all([isinstance(d, dict) for d in ans_dates]):\n",
    "    print('\\u2705 Nice work! You returned a list of dictionaries.')\n",
    "    dates_pts += 1\n",
    "else:\n",
    "    print('\\u274C Check that you returned a list of dictionaries')\n",
    "    \n",
    "# Test if dictionaries have the correct number of values\n",
    "if all([len(d)==2 for d in ans_dates]):\n",
    "    print('\\u2705 Nice work! Your dictionaries all have two values.')\n",
    "    dates_pts += 2\n",
    "else:\n",
    "    print('\\u274C Check that you have a start and end date in each '\n",
    "          'dictionary')\n",
    "    \n",
    "# Test if dictionary values are correct\n",
    "if sum([sum([int(v) for v in d.values()]) for d in chunks]) == date_sum:\n",
    "    print('\\u2705 Nice work! Your dates appear to be correct.')\n",
    "    dates_pts += 2\n",
    "else:\n",
    "    print('\\u274C Check that your dates are correct.')\n",
    "    \n",
    "print('You earned {} of 5 points for generating start and end dates'\n",
    "      .format(dates_pts))\n",
    " \n",
    "dates_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e2b0c3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "51e724de06a7ed83d48e40b3e893fd3d",
     "grade": false,
     "grade_id": "inst-json-name",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Generate JSON file names for each chunk of data\n",
    "\n",
    "Using a `for` loop, iterate over your list of date dictionaries and add a `.json` file name to each dictionary. The file name should be descriptive and unique (i.e. include at least one date).\n",
    "\n",
    "**Please name your files with the provided format string, for example: `MCD15A3H-thomas-2015091-2015120.json.` for the April file.** That way I don't have to download the files multiple times.\n",
    "\n",
    "Call your list of dictionaries at the end for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d5ff1f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fbc56cf160492a6ab9225cf33e36b4c",
     "grade": false,
     "grade_id": "ans-json-name",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# File path template\n",
    "path_tmpl = 'MCD15A3H-thomas-{start_date}-{end_date}.json'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2083324",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f00c9baa6462eaeb20b7b8fe32149443",
     "grade": true,
     "grade_id": "tests-json-name",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ans_json = _\n",
    "json_pts = 0\n",
    "\n",
    "# Test if the data are a list of dictionaries\n",
    "if all([isinstance(d, dict) for d in ans_json]):\n",
    "    print('\\u2705 Nice work! You returned a list of dictionaries.')\n",
    "    json_pts += 1\n",
    "else:\n",
    "    print('\\u274C Check that you returned a list of dictionaries')\n",
    "    \n",
    "# Test if dictionaries have the correct number of values\n",
    "if all([len(d)==3 for d in ans_json]):\n",
    "    print('\\u2705 Nice work! Your dictionaries all have three values.')\n",
    "    json_pts += 2\n",
    "else:\n",
    "    print('\\u274C Check that you have a start and end date in each '\n",
    "          'dictionary as well as a file name')\n",
    "    \n",
    "print('You earned {} of 3 points for generating json file names'\n",
    "      .format(json_pts))\n",
    "json_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd5eb80",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "973e95043c6b768e95527097739246d0",
     "grade": false,
     "grade_id": "instr-url",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Generate a download url for each chunk of data\n",
    "\n",
    "Take a look at the [MODIS Land Products API service documentation](https://modis.ornl.gov/data/modis_webservice.html). Create a download url template string, using:\n",
    "  * The current version\n",
    "  * The subset resource path\n",
    "  * The MCD15A3H product\n",
    "  * latitude, longitude, kmAboveBelow, and kmLeftRight values you generated above\n",
    "\n",
    "> Url query strings begin with `?` and are separated by `&`. For example: `.../subset?latitude=...&longitude=...`\n",
    "\n",
    "Using a `for` loop, go through each of your data chunk dictionaries and add a download url to each. Fill out your template using the startDate and endDate values from your dictionary - they are already correctly formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b3f1ee",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf696b5c36aa37fb45d584c8b3c5afed",
     "grade": false,
     "grade_id": "ans-url",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ef13f0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "836c9bdfc332ceafab27caf4442de8e4",
     "grade": true,
     "grade_id": "tests-url",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ans_url = _\n",
    "url_pts = 0\n",
    "\n",
    "# Test if the data are a list of dictionaries\n",
    "if all([isinstance(d, dict) for d in ans_url]):\n",
    "    print('\\u2705 Nice work! You returned a list of dictionaries.')\n",
    "    url_pts += 1\n",
    "else:\n",
    "    print('\\u274C Check that you returned a list of dictionaries')\n",
    "    \n",
    "# Test if dictionaries have the correct number of values\n",
    "if all([len(d)==4 for d in ans_url]):\n",
    "    print('\\u2705 Nice work! Your dictionaries all have four values.')\n",
    "    url_pts += 2\n",
    "else:\n",
    "    print('\\u274C Check that you have a url in each ditionary')\n",
    "    \n",
    "print('You earned {} of 3 points for generating urls'\n",
    "      .format(url_pts))\n",
    "url_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc8060c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2d75b40aaa1acfdfcb4c62a476382f4d",
     "grade": false,
     "grade_id": "instr-download-modis",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Download and Cache the MODIS data\n",
    "\n",
    "Using a `for` loop, download one MODIS `.json` file for each of your data chunk dictionaries.\n",
    "\n",
    "1. **Download:** You can't do this with earthpy, because this content is not available in the default format that earthpy uses. Instead, use the `get` function from the `requests` library, specifying in the header that you would like content in JSON format:\n",
    "\n",
    "```python\n",
    "response = requests.get(chunk['url'], headers={'Accept': 'application/json'})\n",
    "```\n",
    "\n",
    "2. **Cache:** Use a conditional statement to ensure that you don't download data that you already have. To save JSON data, you can use a **context manager** and the `json` library. For example:\n",
    "    \n",
    "```python\n",
    "with open(chunk['path'], 'w') as json_file:\n",
    "    json.dump(response.json(), json_file)\n",
    "```\n",
    "> So what's going on with the `with` and the `as` and the `open`? You need to open the file with writing permission ('w') before you can write, or \"dump\", JSON into it. By using the **context manager**, or `with/as` statement, you ensure that the file closes when you're done writing. This is important for memory management, so you don't have a bunch of open files taking up valuable space. You'll use a context manager in future assignments for opening lots of files - see [this LiDAR lesson.](https://www.earthdatascience.org/workshops/gis-open-source-python/open-lidar-raster-python/)\n",
    "\n",
    "You don't need to call anything for testing here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d39f14f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16f698a21a82b1fced9b0e893ebe4db9",
     "grade": false,
     "grade_id": "ans-download-modis",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c848836e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e97228462a7283415861235bece20321",
     "grade": true,
     "grade_id": "tests-download-modis",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "modis_download_pts = 0\n",
    "\n",
    "if all([any([os.path.exists(val) for val in d.values()]) for d in ans_json]):\n",
    "    print('\\u2705 Nice work! Your JSON files all exist now.')\n",
    "    modis_download_pts += 5\n",
    "else:\n",
    "    print('\\u274C Check that your download completed.')\n",
    "    \n",
    "print('You earned {} of 5 points for downloading and caching MODIS JSON files'\n",
    "      .format(modis_download_pts))\n",
    "modis_download_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c72d1e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "08a42a269ea72b43d957284138859484",
     "grade": false,
     "grade_id": "inst-load-modis",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 4: Import MODIS JSON files as `xr.DataArray`s\n",
    "\n",
    "This loop is long and tricky! You will need to refer to both the data documentation and likely the documentation of some Python libraries to get it to work. You may also find it helpful to open up one of the JSON files, which you can do in a text editor or web browser. Some tips:\n",
    "  * **Do not attempt to run it all at once**. \n",
    "  * Complete one step at a time, making sure to test that it works\n",
    "  * Make use of the tools you've learned for testing and debugging: print statements, .plot() methods\n",
    "  * Do your tests on a **subset** of your data so it doesn't take long (e.g. once or twice through the loop).\n",
    "  * Read the instructions very carefully! I'm including a lot of the gotchas here, as well as all the new functions you will need.\n",
    "  * You will probably not find a solution to this exact problem on Google. However, there are several examples of how to do parts of this workflow in [the textbook, which is search-able](https://www.earthdatascience.org/search/).\n",
    "\n",
    "### Step 4: Overview\n",
    "Using a `for` loop, import the data you downloaded as `DataArray`s. There are multiple observations in each JSON file, so you will need to have a loop with your loop, or a **nested** loop.\n",
    "\n",
    "### Step 4 Part 1: Loop through each JSON file\n",
    "The following code will need to run for each JSON file. You will need to replace the variable names with the ones you chose. One you successfully do that, the code will:\n",
    "\n",
    "  1. Read in your data from JSON\n",
    "  2. Generate x and y coordinates for your data from the JSON metadata\n",
    "\n",
    "```python\n",
    "#### Read in json data ####\n",
    "# Throw an error if the json file doesn't exist\n",
    "if not os.path.exists(chunk['path']):\n",
    "    raise ValueError('Path to .json file does not exist')\n",
    "# Open JSON file and load contents\n",
    "with open(chunk['path'], 'r') as json_file:\n",
    "    lai_json = json.load(json_file)\n",
    "\n",
    "\n",
    "#### Convert JSON to raster ####\n",
    "# Define coordinates\n",
    "xll, yll = float(lai_json['xllcorner']), float(lai_json['yllcorner'])\n",
    "nrows, ncols = lai_json['nrows'], lai_json['ncols']\n",
    "cellsize = lai_json['cellsize'] \n",
    "\n",
    "x_coords = [xll + cellsize * xi for xi in range(ncols)]\n",
    "y_coords = [yll + cellsize * yi for yi in range(nrows)]\n",
    "y_coords.reverse()\n",
    "```\n",
    "### Step 4 Part 2: Loop through each observation in each JSON file\n",
    "First, write another `for` loop to cycle through each observation (in this case, an observation is a list of data from a single date and band)\n",
    "\n",
    "**Using a conditional statement, make sure that that the 'band' of each observation is 'Lai_500m'.**\n",
    "\n",
    "Next, modify the code below, which will, once correctly modified to match your variable names:\n",
    "  1. Build the data into a DataArray\n",
    "  2. Assign the correct CRS\n",
    "  3. Mask invalid data - you will need to set this variable based on the documentation\n",
    "  4. Scale the data - again, you will need to set this variable based on the documentation\n",
    "  5. Add the DataArray to a list\n",
    "        \n",
    "```python\n",
    "# Add extra dimension to each value\n",
    "date = [pd.to_datetime(obs['calendar_date'])]\n",
    "grid = [np.array_split(obs['data'], nrows)]\n",
    "\n",
    "# Build DataArray\n",
    "lai_da = (\n",
    "    xr.DataArray(\n",
    "        data=grid, \n",
    "        coords={'date': date, 'y': y_coords, 'x': x_coords},\n",
    "        dims=['date', 'y', 'x'],\n",
    "        name='lai')\n",
    "    .rio.write_crs(modis_crs))\n",
    "\n",
    "# Mask NA values\n",
    "lai_masked_da = lai_da.where(lai_da < max_valid)\n",
    "\n",
    "# Multiply by scale factor\n",
    "lai_scaled_da = lai_masked_da * scale_factor\n",
    "\n",
    "# Add DataArray to list for concatenation\n",
    "lai_das.append(lai_scaled_da)\n",
    "```\n",
    "        \n",
    "### Step 4 Part 3: Concatenate\n",
    "Take your list of DataArrays and concatenate (using the .concat() method) into a spatiotemporal DataArray along the 'date' dimension. Check out [this example from the textbook about how to concatenate DataArrays.](https://www.earthdatascience.org/courses/use-data-open-source-python/multispectral-remote-sensing/landsat-in-Python/open-and-crop-data/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cb5a02",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "47043a039c7eaea57b2a6d420531e112",
     "grade": false,
     "grade_id": "ans-load-modis",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f3642b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f5c82f84f2d29ce3847cb857da303ea",
     "grade": true,
     "grade_id": "tests-load-modis",
     "locked": true,
     "points": 25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ans_da = _\n",
    "da_pts = 0\n",
    "\n",
    "if isinstance(ans_da, xr.DataArray):\n",
    "    print('\\u2705 Nice work! You returned a DataArray.')\n",
    "    da_pts += 2\n",
    "else:\n",
    "    print('\\u274C Check that you called your DataArray')\n",
    "\n",
    "if ans_da.size==4831442:\n",
    "    print('\\u2705 Nice work! Your DataArray has the right amount of data.')\n",
    "    da_pts += 5\n",
    "else:\n",
    "    print('\\u274C Check your DataArray size')\n",
    "    \n",
    "if ans_da.shape==(458, 77, 137):\n",
    "    print('\\u2705 Nice work! Your DataArray has the right shape.')\n",
    "    da_pts += 5\n",
    "else:\n",
    "    print('\\u274C Check your DataArray shape')\n",
    "    \n",
    "if (ans_da.min(), ans_da.max())==(0, 7):\n",
    "    print('\\u2705 Nice work! Your DataArray has the right range.')\n",
    "    da_pts += 6\n",
    "else:\n",
    "    print('\\u274C Check your DataArray range')\n",
    "    \n",
    "if round(float(ans_da.mean()), 2)==0.86:\n",
    "    print('\\u2705 Nice work! Your DataArray has the right values.')\n",
    "    da_pts += 7\n",
    "else:\n",
    "    print('\\u274C Check your DataArray values.')\n",
    "    \n",
    "print('You received {} of 25 points for loading your MODIS data.'\n",
    "      .format(da_pts))\n",
    "da_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501dcc52",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a140f663d86452f3673410df137440b1",
     "grade": false,
     "grade_id": "task-plot-check",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Verify your processing with a plot\n",
    "\n",
    "Select the first date after the Thomas Fire stopped burning, and generate a map. Include the Thomas Fire outline to make sure that your data match up.\n",
    "\n",
    "    > You can use `method='backfill'` with the DataSet.sel() method to get the next date if the date you give is between observations. However, there was an observation on the last day of the Thomas Fire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a405cc9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f74d3f4f8bf8e6559cdc71e1154f20c",
     "grade": false,
     "grade_id": "ans-plot-check",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b433bf5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c096ed16ef5ac187d32c942f28ef429",
     "grade": false,
     "grade_id": "instr-outside",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Plot the LAI inside and outside the fire perimeter\n",
    "\n",
    "Create a time series plot of the average LAI inside and outside the Thomas Fire perimeter (but within the envelope of the downloaded data).\n",
    "\n",
    "Start by computing a `GeoDataFrame` of the difference between the Thomas Fire perimeter envelope (e.g. `gdf.envelope`) and the perimeter itself. Call the new `GeoDataFrame` in the cell below\n",
    "\n",
    "> You can use the `.overlay(gdf, how='difference')` method of `GeoDataFrames` to take the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851d18af",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16d4b07b9cd7f554912db10ac54b5f7d",
     "grade": false,
     "grade_id": "ans-outside",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ad3c12",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96e63b007e18ddf1de386ec15fdbdf7c",
     "grade": true,
     "grade_id": "tests-outside",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ans_outside_gdf = _\n",
    "outside_gdf_pts = 0\n",
    "\n",
    "if isinstance(ans_outside_gdf, gpd.GeoDataFrame):\n",
    "    print('\\u2705 Nice work! You returned a GeoDataFrame.')\n",
    "    outside_gdf_pts += 1\n",
    "else:\n",
    "    print('\\u274C Check that you returned a GeoDataFrame')\n",
    "\n",
    "if round(float(ans_outside_gdf.length), 2) == 752360.47:\n",
    "    print('\\u2705 Nice work! Your geometry has the correct length.')\n",
    "    outside_gdf_pts += 4\n",
    "else:\n",
    "    print('\\u274C Check that correctly differenced geometries')\n",
    "    \n",
    "print('You received {} of 5 points for differencing geometries'\n",
    "      .format(outside_gdf_pts))\n",
    "outside_gdf_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06235798",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7cbf650e59c5a1d8c5ce60251e9f0417",
     "grade": false,
     "grade_id": "task-ts-plot",
     "locked": true,
     "points": 25,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "\n",
    "Next, for both the fire perimeter and the area outside the fire perimeter:\n",
    "  1. Clip the LAI to the geometry\n",
    "  2. Take the mean value for each date.\n",
    "  3. Plot both time series on the same axes, with a legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83656032",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc47d5053311a7dd36a9863075d0dde1",
     "grade": false,
     "grade_id": "ans-ts-plot",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92b5839",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c41d25fb9701b8a2de0f06bec3ebcb9c",
     "grade": false,
     "grade_id": "task-explain",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Explain your plot\n",
    "\n",
    "Write an assertion-evidence style headline (as a Markdown Header) and 2-3 bullet points to highlight your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c5e856",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee4f716",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f6222ad595ce6053ecf2de6e3b555dc7",
     "grade": false,
     "grade_id": "task-animation-bonus",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## BONUS plot: Animation (10 pts extra credit)\n",
    "\n",
    "Using a `for` loop, animate each frame of the LAI data from 2017 and 2018 to highlight the change. Check out the second method in this [blog post by Allen Downey on how to do this in Jupyter notebook](https://www.allendowney.com/blog/2019/07/25/matplotlib-animation-in-jupyter/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e5339",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "567d9a35a7ee6ac91d4abe6eca708c5e",
     "grade": false,
     "grade_id": "ans-animation-bonus",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d9d13c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f690ab607d8f9d68e059a1773149293f",
     "grade": false,
     "grade_id": "reproducibility",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "# Reproducibility\n",
    "Notebook runs all the way through. **Make sure to Restart and Run All!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01b7e0d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "37581acc2fec052f8e31126a12dddecb",
     "grade": false,
     "grade_id": "style",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "# Style: PEP-8, Spelling and Grammar, and Comments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
